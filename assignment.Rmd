---
title: "Predicting Exercise Class from Activity Measurements"
author: "TMA"
date: "Tuesday, August 19, 2014"
output:
  html_document:
    highlight: kate
    theme: cerulean
---
========================================

```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F}
# make this an external chunk that can be included in any file
library(knitr)
options(width = 100)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, cache=TRUE, fig.align = 'center', dpi = 100, tidy = F, cache.path = '.cache/', fig.path = 'fig/')

options(xtable.type = 'html')
knit_hooks$set(inline = function(x) {
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})
knit_hooks$set(plot = knitr:::hook_plot_html)
```

========================================

## 1. Summary
The goal of this task was to predict the manner of exercise used by participants in the Weight Lifting Exercises (WLE) Dataset <http://groupware.les.inf.puc-rio.br/har>.

I compared two approaches, both using the random forest method. In the first approach I trained a random forest model on the entire training set. 

The second approach took two steps. First I identified the most important among different groups of variables using four distinct random forest models. Then I built a random forest model on the entire data set using only the variables identified as most important in the first step.

Both approaches resulted in accuracy that rounds to 1.0. The expected out of sample error rates are 0.41% and 0.39%, respectively.


## 2. Data Processing
### The experiment
The WLE data describe an experiment in which the experimenters measured activity on six human participants performing exercises called "dumbbell biceps curls." The experimenters instructed the participants to perform the exercises either properly or improperly, as indicated by five different classes. Class A indicated they performed properly, Classes B, C, D, and E indicated they performed the exercise improperly in specifically defined ways.

The experimenters measured participants' activity from sensors in four locations, including three wearable devices. The locations were on the dumbbells, on a belt worn around the waist, on an arm-band, and on a glove. Each device's metrics included three-axis measures from an accelerometer, a gyroscope, and a magnetometer.

To read more, visit the WLE website: <http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf>.

### The data
The data consists of a preprocessed training data set including 19,622 observations among 160 variables, and a testing data set including 20 observations. The testing data did not label the "classe" variable, the discovery of which was the purpose of this analysis. 

```{r rsubset,cache=TRUE,echo=FALSE}
library(knitr); library(caret); library(randomForest); library(gbm);
library(party);library(ElemStatLearn); library(xtable);
library(MASS);library(plyr); library(survival); library(splines);

setwd("~/GitHub/pml")
training <- read.csv("~/GitHub/pml/pml-training.csv")
testing <- read.csv("~/GitHub/pml/pml-testing.csv")

allColumns <- colnames(training)

# id columns that are not NA in testing data set
availColumns <- cbind(colnames(training),apply(testing, 2, max))
availColumns <- availColumns[is.na(availColumns[,2])==FALSE ,1]
availTrain <- training[, cbind(availColumns)[-c(1,3:6)]]
availTest <- testing[, colnames(testing) %in% colnames(availTrain)]

trainRows <- nrow(availTrain)

wleVariables <- matrix(rep("", 52), nrow=13, ncol = 4)
wleVariables[,1] <- colnames(availTrain)[3:15]
wleVariables[,2] <- colnames(availTrain)[16:28]
wleVariables[,3] <- colnames(availTrain)[29:41]
wleVariables[,4] <- colnames(availTrain)[42:54]
colnames(wleVariables) <- c("Belt", "Arm", "Dumbbells", "Forearm")

set.seed(80302)
subRows1 <- sample(1:trainRows, trainRows/5)
subSet1 <- availTrain[subRows1,]

subRows2 <- sample((1:trainRows)[!(row(availTrain)[,1] %in% subRows1)], (trainRows - length(subRows1))/4)
subSet2 <- availTrain[subRows2,]

subRows3 <- sample((1:trainRows)[!(row(availTrain)[,1] %in% c(subRows1, subRows2))], (trainRows - length(subRows1) - length(subRows2))/3)
subSet3 <- availTrain[subRows3,]

subRows4 <- sample((1:trainRows)[!(row(availTrain)[,1] %in% c(subRows1, subRows2,subRows3))], (trainRows - length(subRows1) - length(subRows2) - length(subRows3))/2)
subSet4 <- availTrain[subRows4,]

subSet5 <- availTrain[(1:trainRows)[!(row(availTrain)[,1] %in% c(subRows1, subRows2,subRows3,subRows4))],]

```

#### Removing non-predictive variables
To eliminate variables not useful in the testing data, I subset the training data to include only variables that did not have "NA" in the testing data, leaving 52 possible predictor variables. These possible predictor variables comprised 13 variables for each of the four measurement locations.

##### Table 1: Predictive Variables
```{r rfSub2,cache=FALSE,echo=FALSE,dependson='rsubset',results='asis'}
library(xtable)
xtab1 <- xtable(wleVariables)
print(xtab1, type = "html", include.rownames = FALSE)
```

I also split the training data equally among five subsets by randomly sampling the "classe" (outcome) variable. The first subset was the training data for each of the location-specific random forest models, as discussed later.

```{r rfMod,cache=TRUE,echo=FALSE,dependson='rsubset'}
set.seed(60614)
rfBelt <- train(classe ~ ., method="rf",data=subSet1[,c(3:15,55)],verbose=FALSE)
rfArm <- train(classe ~ ., method="rf",data=subSet1[,c(16:28,55)],verbose=FALSE)
rfDumbell <- train(classe ~ ., method="rf",data=subSet1[,c(29:41,55)],verbose=FALSE)
rfForearm <- train(classe ~ ., method="rf",data=subSet1[,c(42:54,55)],verbose=FALSE)
rfTrain  <- train(classe ~ ., method="rf",data=availTrain[,c(3:54,55)],verbose=FALSE)
```

## 3. Modeling
### Identify most imporant variables with mini forests
In addition to training a random forest model _rfTrain_ on the entire training set, I also trained four random forest models on the first training data subset, which comprised 20% of the training data. 

I was curious how close I could come to the error rate from _rfTrain_ by combining the best variables identified from location-specific subsets of the variables. I trained all four mini random forests on the first training subset, with each trained model using metrics from only one of the four locations. I named these models _rfBelt_, _rfArm_, _rfDumbell_, and _rfForearm_, where _rfForearm_ referred to measurements at the "glove" location and where, with subconscious irony, I misspelled _rfDumbell_.

## 4. Results
### Important variables
The random forest method grows trees randomly on subsets of the training data and selects the best one based on out of the bag (OOB) cross-validation error rates, so there is no need for the modeler to hold out data to conduct an additional cross validation exercise outside the random forest process.

Among the four mini random forest models, the following variables met the threshold of variable importance greater than 50.

##### Table 2. Most important variables
```{r rfInspect,cache=TRUE,echo=FALSE,dependson=c('rsubset','rfMod'),results='asis'}
library(xtable)

varImpOverall <- rbind(varImp(rfBelt)$importance, varImp(rfArm)$importance, varImp(rfDumbell)$importance, varImp(rfForearm)$importance)

importantVariables2a <- rownames(varImpOverall)[varImpOverall$Overall > 50]

importantVariables2 <- c(rownames(varImpOverall)[varImpOverall$Overall > 50],"classe")

impVar2Matrix <- matrix(importantVariables2a, ncol = 1)
xtable2 <- xtable(impVar2Matrix)

print(xtable2, type = 'html', include.rownames = FALSE)

```

```{r rfTest2,cache=TRUE,echo=FALSE,dependson=c('rsubset','rfMod')}
rfTrain2  <- train(classe ~ ., method="rf",data=availTrain[,importantVariables2],verbose=FALSE)

```

### Final model: rfTrain
_rfTrain_ is the model generated in a single step, training a random forest model on the entire training data set among all 52 predictor variables. 

```{r plot1,cache=TRUE,echo=FALSE,dependson=c('rsubset','rfMod', 'rfTest2'),fig.align='center',fig.width=10,fig.height=8}
library(caret)
rfTrain$finalModel

```

### Final model: rfTrain2
_rfTrain2_ is the model generated in two steps, with the first step training four random forest models on the entire training data set among 13 predictor variables for one device location, and the second step training a single random forest model on the entire training set using only variables whose importance was greater than 50 in the first step. 

```{r plot2,cache=TRUE,echo=FALSE,dependson=c('rsubset','rfMod', 'rfTest2'),fig.align='center',fig.width=10,fig.height=8}
library(caret)
rfTrain2$finalModel

```

## 5. Error prediction
The expected out of sample error rate for _rfTrain_ is 0.41% and for _rfTrain2_ is 0.39%. Both equal their respective OOB error rate, which is an unbiased estimate of out of sample error rate (see <http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr>).

Unlike many other machine learning methods, random forest entails cross validation when building forests so there is no need for a modeler to hold out data for cross validation. (See random forest's documentation on this point at <http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr>)

For either model, the expected likelihood of predicting all 20 test cases correctly on the first attempt is approximately 0.996^20, or 0.92. The expected likelihood of getting all twenty correct after two attempts each is 0.92 + 0.08*0.92 = 0.9936.

```{r plot3,cache=TRUE,echo=FALSE,dependson=c('rsubset','rfMod', 'rfTest2'),fig.align='center',fig.width=10,fig.height=8}
library(caret)
varImp1 <- varImp(rfTrain)
plot(varImp1, top = 10)

varImp2 <- varImp(rfTrain)
plot(varImp2, top = 10)

```
